{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised Learning\n",
    "## DSSP Team\n",
    "## Summer 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA\n",
    "\n",
    "We will consider a _classical_ dataset __decathlon__. It contains the performance of several athletes during two decathlons in 2004 the Decastar and the Olympic Game. Each observation consists of\n",
    "\n",
    "- the 10 raw performance in the 10 events,\n",
    "- the ranking in the event,\n",
    "- the total number of points,\n",
    "- the name of the event.\n",
    "\n",
    "We will mainly focus on the 10 first columns corresponding to the raw athletic performance but will also use the total number of points in some plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "import plotly.graph_objects as go \n",
    "import plotly.io as pio\n",
    "#pio.renderers.default = 'notebook'\n",
    "from sklearn import decomposition #PCA\n",
    "from adjustText import adjust_text #text labels placement\n",
    "from scipy.linalg import sqrtm #square root of a matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decathlon = pd.read_csv('../data/decathlon.txt', sep='\\t')\n",
    "decathlon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decathlon.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pairwise analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1)__ Use `seaborn` to plot the two first coordinates (__100m__ and __Long.jump__) adding the __Points__ information as a color as well as a regression line.\n",
    "\n",
    "__Hint:__ You can use the `'viridis'` palette to have better colors and `adjust_text` to have a better text placement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solution\n",
    "sns.regplot(data=decathlon, x='100m', y='Long.jump', scatter=False);\n",
    "sns.scatterplot(data=decathlon, x='100m', y='Long.jump', hue='Points',\n",
    "palette='viridis')\n",
    "texts = [\n",
    "    plt.text(x, y, s, fontsize=8, horizontalalignment='center', verticalalignment='bottom')\n",
    "    for x, y, s in zip(decathlon['100m'], decathlon['Long.jump'], decathlon.index)]\n",
    "adjust_text(texts, arrowprops=dict(arrowstyle='->', color='k'));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2)__ Do you think those values are correlated?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solution\n",
    "# yes!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__3)__ Compute the correlation matrix between the 10 first variables and display it use a heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solution\n",
    "decathlon.iloc[:,0:10].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solution\n",
    "sns.heatmap(np.abs(decathlon.iloc[:,0:10].corr()));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__4)__ Can you guess which are the most correlated variables and the least ones?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solution\n",
    "#Most correlated: 100.m and Long.jump, Discus and Shot.put..\n",
    "#Least correlated: Pole.vault and 100m, 100m and 1500m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__5)__ Confirm those findings by looking at the pairwise scatterplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solution\n",
    "sns.pairplot(decathlon.iloc[:,0:10]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solution\n",
    "sns.pairplot(decathlon.iloc[:, [0, 2, 5,9]]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3d plot\n",
    "\n",
    "We are now ready to use `plotly` to visualize the dataset in 3d.\n",
    "\n",
    "A 3d scatter plot can be obtained with the following code: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scat = go.Scatter3d(x=decathlon['100m'], y=decathlon['Long.jump'], z=decathlon['Shot.put'],\n",
    "    mode='markers',\n",
    "    marker=dict(color=decathlon['Points'],\n",
    "        colorscale='viridis',\n",
    "        showscale=True))\n",
    "fig = go.Figure()\n",
    "fig.add_trace(scat)\n",
    "fig.update_layout(scene=dict(camera=dict(projection=dict(type='orthographic')),\n",
    "    xaxis=dict(showspikes=False),\n",
    "    yaxis=dict(showspikes=False),\n",
    "    zaxis=dict(showspikes=False),\n",
    "    )\n",
    "    )\n",
    "fig.update_traces()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we have used a orthographic projection rather than a perspective one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__6)__ Play with this interactive graphic to find he projection that appears to lose the less information?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__7)__ This task is similar to the PCA where we look a the subspace that minimizes the error between the data and its projection. Draw the ellipse corresponding to the eigenvectors and the eigenvalues of the covariance matrix to verify this.\n",
    "\n",
    "__Hint:__ Use the `Mesh3d` layer of `plotly` with the `alphahull=0` option and the following ellipse generating code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sphere():\n",
    "    theta = np.arange(-np.pi / 2, np.pi / 2, 0.1)\n",
    "    phi = np.arange(0, 2 * np.pi, 0.1)\n",
    "    x = np.cos(theta[:, None]) * np.cos(phi[None, :])\n",
    "    y = np.cos(theta[:, None]) * np.sin(phi[None ,:])\n",
    "    z = np.sin(theta[:, None]) * np.ones(phi.shape)[None, :]\n",
    "    return(np.vstack((x.flatten(), y.flatten(), z.flatten())).T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ellipse3d(mean, cov):\n",
    "    return(1.95 * sphere().dot(sqrtm(cov))\\\n",
    "        + mean[None, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solution\n",
    "ellipse = ellipse3d(decathlon.iloc[:, 0:3].mean(), decathlon.iloc[:, 0:3].cov())\n",
    "scat = go.Scatter3d(x=decathlon['100m'], y=decathlon['Long.jump'], z=decathlon['Shot.put'],\n",
    "    mode='markers',\n",
    "    marker=dict(color=decathlon['Points'],\n",
    "        colorscale='viridis',\n",
    "        showscale=True))\n",
    "ell = go.Mesh3d(x=ellipse[:, 0], y=ellipse[:, 1], z=ellipse[:, 2],\n",
    "    opacity=.1, alphahull=0)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(scat)\n",
    "fig.add_trace(ell)\n",
    "fig.update_layout(scene=dict(camera=dict(projection=dict(type='orthographic')),\n",
    "    xaxis=dict(showspikes=False),\n",
    "    yaxis=dict(showspikes=False),\n",
    "    zaxis=dict(showspikes=False),\n",
    "    ))\n",
    "fig.update_traces()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__8)__ Can you verify that the best subspace is defined by the direction of the eigenvectors with the largest eigenvalues?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling?\n",
    "\n",
    "So far, we have use the raw performance. That is we compare duration with length as well as 100m time with 1500m time. Obviously, this is not a good idea. All those values should be measured in a common scale. The most classical technique is to _normalize_ by substracting its mean and dividing by the standard deviation. After doing thiw, we may repeat all the previous experiments with those rescaled data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__9)__ Make a copy of the decathlon dataframe and normalize the 10 first columns of this new data frame.\n",
    "\n",
    "__Hint:__ Use `apply` and a lambda function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solution\n",
    "decathlon_scaled = decathlon.copy()\n",
    "decathlon_scaled.iloc[:, 0:10] = decathlon_scaled.iloc[:, 0:10].\\\n",
    "    apply(lambda x: (x - np.mean(x)) / np.std(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solution\n",
    "decathlon_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__10)__ Plot the corresponding scatter plot and compare it with the one obtained with the raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solution\n",
    "sns.regplot(data=decathlon_scaled, x='100m', y='Long.jump', scatter=False);\n",
    "sns.scatterplot(data=decathlon_scaled, x='100m', y='Long.jump', hue='Points')\n",
    "texts = [\n",
    "    plt.text(x, y, s, fontsize=8, horizontalalignment='center', verticalalignment='bottom')\n",
    "    for x, y, s in zip(decathlon_scaled['100m'], decathlon_scaled['Long.jump'], decathlon_scaled.index)]\n",
    "adjust_text(texts, arrowprops=dict(arrowstyle='->', color='k'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solution\n",
    "sns.regplot(data=decathlon, x='100m', y='Long.jump', scatter=False);\n",
    "sns.scatterplot(data=decathlon, x='100m', y='Long.jump', hue='Points')\n",
    "texts = [\n",
    "    plt.text(x, y, s, fontsize=8, horizontalalignment='center', verticalalignment='bottom')\n",
    "    for x, y, s in zip(decathlon['100m'], decathlon['Long.jump'], decathlon.index)]\n",
    "adjust_text(texts, arrowprops=dict(arrowstyle='->', color='k'));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__11)__ What if one imposes _equal_ axis?\n",
    "\n",
    "__Hint:__ Use `plt.axis('equal')`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solution\n",
    "sns.regplot(data=decathlon, x='100m', y='Long.jump', scatter=False);\n",
    "sns.scatterplot(data=decathlon, x='100m', y='Long.jump', hue='Points')\n",
    "texts = [\n",
    "    plt.text(x, y, s, fontsize=8, horizontalalignment='center', verticalalignment='bottom')\n",
    "    for x, y, s in zip(decathlon['100m'], decathlon['Long.jump'], decathlon.index)]\n",
    "adjust_text(texts, arrowprops=dict(arrowstyle='->', color='k'))\n",
    "plt.axis('equal');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solution\n",
    "sns.regplot(data=decathlon_scaled, x='100m', y='Long.jump', scatter=False);\n",
    "sns.scatterplot(data=decathlon_scaled, x='100m', y='Long.jump', hue='Points')\n",
    "texts = [\n",
    "    plt.text(x, y, s, fontsize=8, horizontalalignment='center', verticalalignment='bottom')\n",
    "    for x, y, s in zip(decathlon_scaled['100m'], decathlon_scaled['Long.jump'], decathlon_scaled.index)]\n",
    "adjust_text(texts, arrowprops=dict(arrowstyle='->', color='k'))\n",
    "plt.axis('equal');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__12)__ Repeat the same experiment replacing the `100m` by the `1500m`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solution\n",
    "sns.regplot(data=decathlon, x='1500m', y='Long.jump', scatter=False);\n",
    "sns.scatterplot(data=decathlon, x='1500m', y='Long.jump', hue='Points')\n",
    "texts = [\n",
    "    plt.text(x, y, s, fontsize=8, horizontalalignment='center', verticalalignment='bottom')\n",
    "    for x, y, s in zip(decathlon['1500m'], decathlon['Long.jump'], decathlon.index)]\n",
    "adjust_text(texts, arrowprops=dict(arrowstyle='->', color='k'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solution\n",
    "sns.regplot(data=decathlon_scaled, x='1500m', y='Long.jump', scatter=False);\n",
    "sns.scatterplot(data=decathlon_scaled, x='1500m', y='Long.jump', hue='Points')\n",
    "texts = [\n",
    "    plt.text(x, y, s, fontsize=8, horizontalalignment='center', verticalalignment='bottom')\n",
    "    for x, y, s in zip(decathlon_scaled['1500m'], decathlon_scaled['Long.jump'], decathlon_scaled.index)]\n",
    "adjust_text(texts, arrowprops=dict(arrowstyle='->', color='k'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solution\n",
    "sns.regplot(data=decathlon, x='1500m', y='Long.jump', scatter=False);\n",
    "sns.scatterplot(data=decathlon, x='1500m', y='Long.jump', hue='Points')\n",
    "texts = [\n",
    "    plt.text(x, y, s, fontsize=8, horizontalalignment='center', verticalalignment='bottom')\n",
    "    for x, y, s in zip(decathlon['1500m'], decathlon['Long.jump'], decathlon.index)]\n",
    "adjust_text(texts, arrowprops=dict(arrowstyle='->', color='k'))\n",
    "plt.axis('equal');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solution\n",
    "sns.regplot(data=decathlon_scaled, x='1500m', y='Long.jump', scatter=False);\n",
    "sns.scatterplot(data=decathlon_scaled, x='1500m', y='Long.jump', hue='Points')\n",
    "texts = [\n",
    "    plt.text(x, y, s, fontsize=8, horizontalalignment='center', verticalalignment='bottom')\n",
    "    for x, y, s in zip(decathlon_scaled['1500m'], decathlon_scaled['Long.jump'], decathlon_scaled.index)]\n",
    "adjust_text(texts, arrowprops=dict(arrowstyle='->', color='k'))\n",
    "plt.axis('equal');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__13)__ What about the correlation matrix, the pairwise scatterplots and the 3d plot?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solution\n",
    "decathlon_scaled.iloc[:,1:10].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solution\n",
    "sns.pairplot(decathlon_scaled.iloc[:,0:10]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solution\n",
    "ellipse = ellipse3d(decathlon_scaled.iloc[:, 0:3].mean(), decathlon_scaled.iloc[:, 0:3].cov())\n",
    "scat = go.Scatter3d(x=decathlon_scaled['100m'], y=decathlon_scaled['Long.jump'], z=decathlon_scaled['Shot.put'],\n",
    "    mode='markers',\n",
    "    marker=dict(color=decathlon_scaled['Points'],\n",
    "        colorscale='viridis',\n",
    "        showscale=True))\n",
    "ell = go.Mesh3d(x=ellipse[:, 0], y=ellipse[:, 1], z=ellipse[:, 2],\n",
    "    opacity=.1, alphahull=0)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(scat)\n",
    "fig.add_trace(ell)\n",
    "fig.update_layout(scene=dict(camera=dict(projection=dict(type='orthographic')),\n",
    "    xaxis=dict(showspikes=False),\n",
    "    yaxis=dict(showspikes=False),\n",
    "    zaxis=dict(showspikes=False),\n",
    "    ))\n",
    "fig.update_traces()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principal Component Analysis\n",
    "\n",
    "The library `scikit-learn` contains a PCA function that we are going to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_scaled = decomposition.PCA(n_components=10).fit(decathlon_scaled.iloc[:, 0:10])\n",
    "decathlon_scaled_pca = pca_scaled.transform(decathlon_scaled.iloc[:, 0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pca_scaled` contains the all the information computed by the PCA (for instance the eigenvalues in the field `singular_values_`, the change of basis matrix in `components_`) and `decathlon_scaled_pca` contains the coordinates of `decathlon_scaled` in the PCA basis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__14)__ Verify the the coordinates in the PCA basis can be obtained by a product between the coordinates in the old basis and the change of basis matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solution\n",
    "np.max(np.abs(decathlon_scaled_pca - decathlon_scaled.iloc[:, 0:10].values.dot(pca_scaled.components_.T)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__15)__ Plot the points in the new coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solution\n",
    "decathlon_scaled_pca_df = pd.DataFrame({'X': decathlon_scaled_pca[:, 0],\n",
    "    'Y': decathlon_scaled_pca[:, 1]},\n",
    "    index = decathlon.index)\n",
    "decathlon_scaled_pca_df['Points'] = decathlon['Points']\n",
    "sns.scatterplot(data=decathlon_scaled_pca_df, x='X', y='Y', hue='Points', palette='viridis')\n",
    "texts = [\n",
    "    plt.text(x, y, s, fontsize=8, horizontalalignment='center', verticalalignment='bottom')\n",
    "    for x, y, s in zip(decathlon_scaled_pca_df['X'], decathlon_scaled_pca_df['Y'], decathlon_scaled_pca_df.index)]\n",
    "adjust_text(texts, arrowprops=dict(arrowstyle='->', color='k'))\n",
    "plt.legend(bbox_to_anchor=(1.01, 0.5), loc='center left')\n",
    "plt.axis('equal');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__16)__ In statistics, one often looks at the correlation between the new axis and the old ones. This can be computed in Python with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decathlon_scaled_pca_nor = decathlon_scaled_pca/np.sqrt((decathlon_scaled_pca ** 2).sum(axis=0))\n",
    "decathlon_scaled_nor = decathlon_scaled.iloc[:, 0:10]/np.sqrt((decathlon_scaled.iloc[:, 0:10] ** 2).sum(axis=0))\n",
    "decathlon_corr_circle = decathlon_scaled_pca_nor.T.dot(decathlon_scaled_nor)\n",
    "decathlon_corr_circle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that by construction the norm of the correlation vector for a given original axis is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(decathlon_corr_circle ** 2).sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the correlation of the original axes with the two first new components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solution\n",
    "pcs = decathlon_corr_circle\n",
    "fig, ax = plt.subplots()\n",
    "for i, (x, y) in enumerate(zip(pcs[0, :], pcs[1, :])):\n",
    "    plt.arrow(0, 0, x, y, head_width=.05, color='k')\n",
    "texts = [ \n",
    "    plt.text(x, y, decathlon_scaled.columns[i])\n",
    "    for i, (x, y) in enumerate(zip(pcs[0, :], pcs[1, :]))\n",
    "]\n",
    "#adjust_text(texts, arrowprops=dict(arrowstyle='->', color='k'))\n",
    "plt.plot([-1, 1], [0, 0], color='grey', ls='--')\n",
    "plt.plot([0, 0], [-1, 1], color='grey', ls='--')\n",
    "plt.xlim([-1, 1])\n",
    "plt.ylim([-1, 1])\n",
    "plt.axis('equal')\n",
    "plt.grid(b=None)\n",
    "plt.gca().axison = False\n",
    "circle = plt.Circle((0, 0), 1, facecolor='none', edgecolor='grey')\n",
    "ax.add_patch(circle);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__17)__ Which variables are well captured? Can you interpret the new axes (the horizontal and the vertical ones)? \n",
    "Can you explain why the long jump appears to be the opposite of the 100m?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solution\n",
    "decathlon_mod = decathlon.copy()\n",
    "decathlon_mod['100m'] = 100 / decathlon_mod['100m'] \n",
    "decathlon_mod['400m'] = 400 / decathlon_mod['400m']\n",
    "decathlon_mod['110m.hurdle'] = 110 / decathlon_mod['110m.hurdle']\n",
    "decathlon_mod['1500m'] = 1500 / decathlon_mod['1500m'] \n",
    "decathlon_mod_scaled = decathlon_mod.copy()\n",
    "decathlon_mod_scaled.iloc[:, 0:10] = decathlon_mod_scaled.iloc[:, 0:10].\\\n",
    "    apply(lambda x: (x - np.mean(x)) / np.std(x))\n",
    "pca_scaled = decomposition.PCA(n_components=10).fit(decathlon_mod_scaled.iloc[:, 0:10])\n",
    "decathlon_mod_scaled_pca = pca_scaled.transform(decathlon_mod_scaled.iloc[:, 0:10])\n",
    "decathlon_mod_scaled_pca_nor = decathlon_mod_scaled_pca/np.sqrt((decathlon_mod_scaled_pca ** 2).sum(axis=0))\n",
    "decathlon_mod_scaled_nor = decathlon_mod_scaled.iloc[:, 0:10]/np.sqrt((decathlon_mod_scaled.iloc[:, 0:10] ** 2).sum(axis=0))\n",
    "decathlon_corr_circle = decathlon_mod_scaled_pca_nor.T.dot(decathlon_mod_scaled_nor)\n",
    "pcs = decathlon_corr_circle\n",
    "fig, ax = plt.subplots()\n",
    "for i, (x, y) in enumerate(zip(pcs[0, :], pcs[1, :])):\n",
    "    plt.arrow(0, 0, x, y, head_width=.05, color='k')\n",
    "texts = [ \n",
    "    plt.text(x, y, decathlon_mod_scaled.columns[i])\n",
    "    for i, (x, y) in enumerate(zip(pcs[0, :], pcs[1, :]))\n",
    "]\n",
    "#adjust_text(texts, arrowprops=dict(arrowstyle='->', color='k'))\n",
    "plt.plot([-1, 1], [0, 0], color='grey', ls='--')\n",
    "plt.plot([0, 0], [-1, 1], color='grey', ls='--')\n",
    "plt.xlim([-1, 1])\n",
    "plt.ylim([-1, 1])\n",
    "plt.axis('equal')\n",
    "plt.grid(b=None)\n",
    "plt.gca().axison = False\n",
    "circle = plt.Circle((0, 0), 1, facecolor='none', edgecolor='grey')\n",
    "ax.add_patch(circle);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__18)__ Plot the cumulative percentage of inertia. Do you think using 2 dimensions is enough here?\n",
    "\n",
    "__Hint:__ The inertia is also called the explained variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solution\n",
    "plt.bar(np.arange(1, 11), pca_scaled.explained_variance_ratio_.cumsum())\n",
    "plt.xlabel('Dim.')\n",
    "plt.ylabel('Cumlative percentage of inertia');\n"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit ('DS': conda)",
   "language": "python",
   "name": "python38264bitdsconda6e231da8c3e14958b9b66a19bb952944"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}